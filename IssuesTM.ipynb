{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "from IPython.display import display, HTML\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "# Install the required libraries\n",
        "!pip install pyLDAvis --upgrade\n",
        "!pip install gensim pandas nltk\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')  # Download the stopwords dataset\n",
        "\n",
        "# Load your CSV containing the emails and issues\n",
        "df = pd.read_csv('/content/customer_service_email_issues1.csv')  # Update with your dataset path\n",
        "\n",
        "# --- The issue is that 'email' and 'issue' are likely in one column, separated by ';' ---\n",
        "# Split the single column into two columns named 'email' and 'issue'\n",
        "df[['email', 'issue']] = df.iloc[:, 0].str.split(';', expand=True)\n",
        "# --- Now you should have separate 'email' and 'issue' columns ---\n",
        "\n",
        "# Print the column names to verify the actual names in your CSV\n",
        "print(df.columns)\n",
        "\n",
        "# Function to clean text data and remove non-relevant issues\n",
        "def clean_issue(issue):\n",
        "    # Remove special tokens and placeholders (e.g., \"<|end_header_id|>\")\n",
        "    issue = re.sub(r'<\\|.*?\\|>', '', issue)\n",
        "    # Remove non-alphanumeric characters and extra spaces\n",
        "    issue = re.sub(r'[^a-zA-Z\\s]', '', issue)\n",
        "    # Convert text to lowercase and remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    issue = ' '.join([word for word in issue.lower().split() if word not in stop_words])\n",
        "    # Remove very short or non-meaningful issues\n",
        "    if len(issue.split()) < 2:  # Keep issues with at least 2 words\n",
        "        return None\n",
        "    return issue\n",
        "\n",
        "# Function to merge similar issues based on semantic meaning\n",
        "def merge_similar_issues(issue):\n",
        "    # Handle None values before processing\n",
        "    if issue is None:\n",
        "        return None\n",
        "\n",
        "    issue_mapping = {\n",
        "        \"dropped calls\": [\"dropping calls\", \"dropped phone calls\", \"calls dropped\", \"calls dropping frequently\"],\n",
        "        \"intermittent disconnections\": [\"frequent disconnections\", \"intermittent outages\", \"intermittent disconnects\"],\n",
        "        \"phone ringing\": [\"phone connection drops\", \"phone ringing issues\"],\n",
        "        # Add more mappings as necessary for other similar issues\n",
        "    }\n",
        "\n",
        "    # Check each mapping and replace similar phrases with the standard one\n",
        "    for main_issue, similar_issues in issue_mapping.items():\n",
        "        for similar in similar_issues:\n",
        "            if similar in issue:\n",
        "                return main_issue\n",
        "    return issue\n",
        "\n",
        "# Apply cleaning to the 'issue' column\n",
        "df['clean_issue'] = df['issue'].dropna().apply(clean_issue)\n",
        "\n",
        "# Apply merging of similar issues\n",
        "df['clean_issue'] = df['clean_issue'].apply(merge_similar_issues)\n",
        "\n",
        "# Drop rows with empty or None values after cleaning and merging\n",
        "df = df.dropna(subset=['clean_issue'])\n",
        "\n",
        "# Create a list of cleaned issues\n",
        "issues = df['clean_issue'].tolist()\n",
        "\n",
        "# Create a list of documents, treating each issue as a single token (since you want one issue per document)\n",
        "documents = [[issue] for issue in issues]\n",
        "\n",
        "# Create a dictionary and corpus for PyLDA\n",
        "dictionary = corpora.Dictionary(documents)\n",
        "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
        "\n",
        "# PyLDA Topic Modeling\n",
        "num_topics = 5  # Define the number of topics\n",
        "lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
        "\n",
        "# Print the topics found by PyLDA\n",
        "print(\"PyLDA Topics:\")\n",
        "for idx, topic in lda_model.print_topics(num_topics=num_topics):\n",
        "    print(f\"Topic {idx}: {topic}\")\n",
        "\n",
        "# Visualization of topics using pyLDAvis\n",
        "vis_data = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
        "\n",
        "# Save the visualization to an HTML file\n",
        "output_html = '/content/lda_visualization.html'  # Specify your desired output file path\n",
        "pyLDAvis.save_html(vis_data, output_html)\n",
        "\n",
        "# Display a link to download the saved HTML visualization\n",
        "#display(HTML(f'<a href=\"{output_html}\" target=\"_blank\">Click here to view the PyLDAvis visualization</a>'))\n",
        "\n",
        "# Alternatively, display the saved HTML file directly in Colab (should work for Colab users)\n",
        "#display(HTML(output_html))\n",
        "\n",
        "#The pyLDA visualization is generated in a html file in the working directory for download and the PyLDA topics present in it are displayed below\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDrEOytbhMTC",
        "outputId": "77b4d815-313e-4e3a-da68-20ecea091079"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.4)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.10.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.5.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.16.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['email;issue', 'email', 'issue'], dtype='object')\n",
            "PyLDA Topics:\n",
            "Topic 0: 0.799*\"dial tone\" + 0.128*\"intermittent disconnections\" + 0.037*\"dropped calls frequently\" + 0.006*\"cant make calls\" + 0.006*\"dropped calls\" + 0.006*\"phone ringing\" + 0.006*\"exact problem\" + 0.006*\"incoming calls\" + 0.006*\"poor signal strength\"\n",
            "Topic 1: 0.379*\"incoming calls\" + 0.379*\"cant make calls\" + 0.035*\"dropped calls\" + 0.035*\"dial tone\" + 0.035*\"exact problem\" + 0.035*\"phone ringing\" + 0.035*\"dropped calls frequently\" + 0.035*\"intermittent disconnections\" + 0.034*\"poor signal strength\"\n",
            "Topic 2: 0.426*\"poor signal strength\" + 0.075*\"dropped calls\" + 0.072*\"dial tone\" + 0.071*\"exact problem\" + 0.071*\"phone ringing\" + 0.071*\"dropped calls frequently\" + 0.071*\"intermittent disconnections\" + 0.071*\"incoming calls\" + 0.071*\"cant make calls\"\n",
            "Topic 3: 0.112*\"dropped calls\" + 0.112*\"exact problem\" + 0.111*\"phone ringing\" + 0.111*\"dial tone\" + 0.111*\"dropped calls frequently\" + 0.111*\"intermittent disconnections\" + 0.111*\"cant make calls\" + 0.111*\"incoming calls\" + 0.111*\"poor signal strength\"\n",
            "Topic 4: 0.916*\"dropped calls\" + 0.040*\"phone ringing\" + 0.022*\"exact problem\" + 0.004*\"dial tone\" + 0.004*\"intermittent disconnections\" + 0.004*\"dropped calls frequently\" + 0.004*\"incoming calls\" + 0.004*\"cant make calls\" + 0.004*\"poor signal strength\"\n"
          ]
        }
      ]
    }
  ]
}